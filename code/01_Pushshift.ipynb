{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Project - 01: Pushshift Requests\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import regex\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filename format log - function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_format_log(file_path, \n",
    "                        logfile = '../data/file_log.txt', \n",
    "                        now = round(time.time()), \n",
    "                        file_description = None): \n",
    "    try:\n",
    "        ext = re.search('(?<!^)(?<!\\.)\\.(?!\\.)', file_path).start() \n",
    "    except:\n",
    "        raise NameError('Please enter a relative path with a file extension.') \n",
    "    stamp = re.search('(?<!^)(?<!\\.)[a-z]+_[a-z]+(?=\\.)', file_path).start()\n",
    "    formatted_name = f'{file_path[:stamp]}{now}_{file_path[stamp:]}'  \n",
    "    if not file_description:\n",
    "        file_description = f'Pull: {time.asctime(time.gmtime(now))}'\n",
    "    with open(logfile, 'a+') as f:\n",
    "        f.write(f'{formatted_name}: {file_description}\\n')\n",
    "    return formatted_name, now, file_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Query Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function was made by a collaboration with Hovanes Gasparian and Rene Wilkening.  May contain artifacts\n",
    "def reddit_query(subreddits, n_samples=1000, after=None):\n",
    "    global before\n",
    "    url = f'https://api.pushshift.io/reddit/search/submission'\n",
    "    last_comment = round(time.time())\n",
    "    comment_list = []\n",
    "    run = 1\n",
    "    while len(comment_list) < n_samples:\n",
    "        try:\n",
    "            params = {\n",
    "              'subreddit': subreddits,\n",
    "              'sort':'desc',\n",
    "              'size':n_samples,\n",
    "              'before':before,\n",
    "              'after':after,\n",
    "             }\n",
    "            response = requests.get(url, params = params)\n",
    "            posts = response.json()['data']\n",
    "            if len(posts) == 0:\n",
    "                last_comment = last_comment\n",
    "            else:\n",
    "                last_comment = posts[-1]['created_utc']\n",
    "                comment_list.extend(posts)\n",
    "                timestamp = posts[-1]['created_utc']\n",
    "                time.sleep(1) \n",
    "                run += 1\n",
    "        except:\n",
    "            if response.status_code != 200:\n",
    "                return f'Check status. Error code: {response.status_code}'\n",
    "            else:\n",
    "                return 'Error. Pull not completed.'\n",
    "    formatted_name, now, file_description = filename_format_log(file_path =f'../data/raw_{subreddits}.json', now=timestamp)\n",
    "    with open(formatted_name, 'w+') as f:\n",
    "        json.dump(comment_list, f)\n",
    "        #df_sp = pd.DataFrame(comment_list)\n",
    "        # spir_list = comment_list\n",
    "        \n",
    "    before =timestamp\n",
    "    \n",
    "    print(f'Saved and completed query and returned {len(comment_list)} submissions.')\n",
    "    print(f'Reddit text is ready for processing.')\n",
    "    return print(f'Last timestamp was {timestamp}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 10 sets of 1000 rows from the 'spirituality' Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting query 0\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1578716144.\n",
      "Starting query 1\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1577188855.\n",
      "Starting query 2\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1575495943.\n",
      "Starting query 3\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1573755045.\n",
      "Starting query 4\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1571674913.\n",
      "Starting query 5\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1569697881.\n",
      "Starting query 6\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1567584046.\n",
      "Starting query 7\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1565651408.\n",
      "Starting query 8\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1563667320.\n",
      "Starting query 9\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1561247413.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Starting query\", i)\n",
    "    reddit_query('spirituality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 10 sets of 1000 rows from the 'meditation' Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting query 0\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1559216363.\n",
      "Starting query 1\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1557115758.\n",
      "Starting query 2\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1554908037.\n",
      "Starting query 3\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1552846578.\n",
      "Starting query 4\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1550974135.\n",
      "Starting query 5\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1549381649.\n",
      "Starting query 6\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1547931148.\n",
      "Starting query 7\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1546480038.\n",
      "Starting query 8\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1544730945.\n",
      "Starting query 9\n",
      "Saved and completed query and returned 1000 submissions.\n",
      "Reddit text is ready for processing.\n",
      "Last timestamp was 1543267198.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Starting query\", i)\n",
    "    reddit_query('meditation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
